# Spiking Orchestrator (SORCH): SNN駆動型・自律対話エージェント 仕様書

## 1. プロジェクト概要
### 1.1. 目的
単に言葉を生成するチャットボットではなく、人間のような**「会話の間（ま）」「テンポ」「割り込みへの反応」**を備えた、生物的な実在感のあるAIエージェントを構築する。
**最重要目標は、エンドツーエンド（マイク入力〜音声停止）の実測遅延 30-50ms の達成と、誤検知（咳払い等への反応）の排除である。**
また、平均遅延だけでなく**95th/99thパーセンタイル（テールレイテンシ）**を管理し、体験のばらつき（ジッタ）を抑える。

### 1.2. コア・コンセプト：Bi-Level Architecture & Split Core
システムを「道具（Tools）」と「中枢（Core）」に分離し、さらに中枢内部を「反射（固定）」と「記憶（可塑）」に分割することで、堅牢性と柔軟性を両立する。
* **Tools:** HuBERT, RWKV, VOICEVOX (すべて既存モデル・APIを利用)。
* **Core:** 軽量SNN。ここが**SORCH**の本体であり、Python (SpikingJelly) 上で動作する。

## 2. システムアーキテクチャ
| レイヤー | モジュール名 | 役割 (Role) & 実装要件 |
| :--- | :--- | :--- |
| **感覚層** | **Multi-Feature Sensory** | 音声を「物理的特徴（音量・ピッチ・スペクトル）」と「意味（ベクトル）」に分離入力。 |
| **中枢層** | **Orchestrator Core** | **【開発の核心】** 以下の2領域による協調制御。<br>1. **Reflex Circuit** (反射・安全装置)<br>2. **Hippocampal Reservoir** (短期記憶・文脈) |
| **思考層** | **Cognitive Engine** | RWKV (Frozen)。中枢からのリクエスト時のみ推論を行う。 |
| **運動層** | **Motor Cortex** | **Chunk-based TTS**。短い単位での生成と、バッファ即時破棄機能を持つ。 |

## 3. モジュール詳細仕様：Orchestrator Core
中枢層は時間解像度 $\Delta t = 1.0 \text{ms}$ (推奨) で動作するSNNシミュレーションである。
クリティカルパスの遅延安定性のため、Pythonのメインループではなく**マルチプロセス（共有メモリ/Lock-free Ring Buffer）**での実装を推奨する。

### 3.1. 領域1: Reflex Circuit (反射回路)
* **役割:** 割り込み検知と即時停止。
* **特性:** 重み固定。誤検知を防ぐための**不感期（Hold-off）**に加え、**環境適応性**と**自己発話抑制**を持つ。
* **入力:** 多次元特徴量アンサンブル (Envelope, ZCR, Spectral Centroid, Voicing Flag)。
* **出力:** `Stop_Signal` (運動層への抑制スパイク)。
* **誤検知対策 (Robustness Logic):**
    1.  **不感期 (Hold-off):** Stop信号発火後、**200-500ms** の不感期を設け、チャタリングを防止する（状況依存で可変とする）。
    2.  **SNR適応閾値 (Adaptive Threshold):** 以下の指数移動平均を用いて動的閾値を設定する。
        $$V_{th}(t) = \mu_{\text{noise}}(t) + \alpha, \quad \mu_{\text{noise}}(t) = (1-\gamma)\mu_{\text{noise}}(t-1) + \gamma E(t)$$
        ※ $\gamma$: 減衰係数（時定数1秒相当）、$E(t)$: 非音声区間のエネルギー
    3.  **ループバック検知 (Loopback/Echo Suppression):** 単なるフラグだけでなく、**AEC (Acoustic Echo Cancellation)** または近接マイクの差分検出を併用し、自身の音声を確実にマスクする。

### 3.2. 領域2: Hippocampal Reservoir (海馬リザーバ)
* **役割:** 短期記憶（会話の勢い、相槌タイミング）。
* **特性:** **STP (Short-Term Plasticity)** 実装。
* **入力:** `Semantic_Vector` (意味) + `Reflex_Output` (反射回路の状態)。
* **Readout:** 高次元状態ベクトルをランダム射影等で圧縮し、**RLS (Recursive Least Squares)** でアクションを決定。
    * **安定化策:** RLSには **忘却係数 $\lambda$ (0.99-0.999)** と **Tikhonov正則化** を導入し、数値的安定性を確保する。

## 4. 運動層仕様 (Motor Cortex)
1.  **ストリーミング再生 (Chunking):** 音声を一括生成せず、短いチャンク（200-500ms単位）で順次生成・再生する。
2.  **即時キャンセル (Hard Stop):** Reflexからの `Stop_Signal` を受信した瞬間、**「再生キューのクリア」**と**「オーディオデバイスのリセット」**を実行する（APIレベルでのプリエンプティブ性の確認必須）。

---

## 5. 開発ロードマップ (Detailed)

「まず実測し、現実を知る」ことから開始し、最終的に自律的な対話を実現する。

### Phase 1: ベンチマークと反射回路の実装
**目的:** エンドツーエンド遅延の実測と、誤検知のない割り込み機能の実現。

* **Step 1.0: 遅延計測ベンチマーク (Must Do First)**
    * 単純な「マイク入力 → 閾値判定 → スピーカー停止命令」のループスクリプトを作成。
    * **レイテンシ予算の分解と計測:**
        1. マイク取り込み〜フレーム確定: 目標 1-3ms
        2. 前処理 (Feature Extraction): 目標 1-5ms
        3. 判定 (Inference): 目標 < 1ms
        4. 出力停止実行 (OS/Driver): 目標 1-5ms
    * **判定基準:** Median Latency < 50ms かつ **p99 < 100ms**。未達の場合は C++/Rust ネイティブ実装へ移行。
* **Step 1.1: Reflex Circuit のプロトタイプ (Classical DSP First)**
    * SNNの最適化には時間がかかるため、まずは**古典的信号処理（VAD + 適応閾値）**で反射回路を実装し、遅延とFP/FNのベースラインを確定させる。
    * これと並行してSNNモデルの研究開発を進める。
* **Step 1.2: 停止制御の実装**
    * VOICEVOX CORE等のAPIを確認し、バッファ破棄を含む安全な停止処理を実装する。

### Phase 2: 記憶回路と文脈制御
**目的:** 会話の「間」と「文脈」を液状記憶（Reservoir）として実装する。ここでは**STP（短期可塑性）の挙動**を作り込むことが主眼となる。

* **Step 2.1: カスタムSTPニューロンの実装**
    * **内容:** SpikingJellyの `BaseNode` を継承し、Tsodyks-Markramモデルの微分方程式（$du/dt, dx/dt$）を内部状態として持つ `STP_LIFNode` クラスを作成する。
* **Step 2.2: Memory Capacity (MC) の最大化探索**
    * **内容:** 500〜1000個のニューロンを持つリザーバ層を構築。ランダムな入力パターンを流し込み、過去の入力が現在のリザーバ状態からどれだけ復元できるかを計測する。
    * **探索パラメータ:** $\tau_F$ (100-800ms), $\tau_D$ (500-3000ms), $W_{scale}$ (0.8-1.1)。
* **Step 2.3: Readout層の実装と次元削減**
    * **設計:** Readoutが参照する状態ベクトルは、膜電位 `v` だけでなく **spike** や **STP内部状態（u/r/eff）** を含める候補を比較し、MCなどの指標で採否を決める。
    * **補足:** 状態を増やすほど性能（MC）は伸びやすい一方、次元が増えて計算が重くなる。必要なら Random Projection で圧縮し、性能と軽さのトレードオフで決める。
    * **対策:** **ランダム射影 (Random Projection)** を用い、状態ベクトルを低次元に圧縮してからReadout層に入力する。計算コストの高いPCAは避ける。
	* **暫定推奨（実装運用）:** 軽さ優先の現実案として `state_mode=v+spike` + `proj_out_dim=200` を基準に進める。
* **Step 2.4: オンライン学習 (RLS) の導入**
    * **内容:** ユーザーごとの会話テンポに適応するため、Readout層の重みを RLS (with forgetting factor) でリアルタイム更新する。更新間隔は 10-50ms を目安とする。

### Phase 3: システム統合と非同期制御
**目的:** 耳・脳・口を並列動作させ、実用的な応答速度を持つ対話システムとして組み上げる。

* **Step 3.1: マルチプロセス・アーキテクチャの構築**
    * **内容:** PythonのGIL回避のため、`multiprocessing` を用いてプロセス分離を行う。
        1.  **Audio Process:** マイク/スピーカー (High Priority / RT Kernel推奨)。
        2.  **Core Process:** SNN/Reflex Logic。
        3.  **Cognitive Process:** RWKV/HuBERT。
* **Step 3.2: Lock-free Queue による通信**
    * **内容:** プロセス間通信には遅延の少ない **Lock-free Ring Buffer (SPSC)** 等を採用する。
* **Step 3.3: 優先度付き制御ロジック**
    * **内容:** `Motor Cortex` において、Stop信号を物理レベルで優先するロジックを実装。

### Phase 4: UX向上と常駐化
* **Step 4.1: 脳波モニター (Brain Visualizer) の作成**
* **Step 4.2: 会話パラメータの感覚的チューニング**

## 6. 評価指標 (KPI)

開発の進捗は以下の数値で管理する。**特にテールレイテンシとジッタを重視する。**

1.  **Latency (遅延):**
    * Stop Latency: **Median < 50ms**, **p95 < 80ms**, **p99 < 100ms**
    * Jitter (標準偏差): 小さいほど良い
2.  **Safety (誤検知):**
    * False Positive Rate: **< 0.5回 / 分** (実環境での長期テスト必須)
    * False Negative Rate: **< 5%**
3.  **Experience (体験):**
    * Sputtering: **0回** (不感期による制御)

## 7. 開発環境・技術スタック

* **言語:** Python 3.12 (ホットパスの Cython/Numba 化、または C++/Rust への移行を視野)
* **SNNライブラリ:** SpikingJelly
* **Audio I/O:**
    * Linux: **JACK** または ALSA (バッファサイズ 64-128 samples推奨)
    * Windows: ASIO / WASAPI-Exclusive
    * Library: `PyAudio` (要低遅延設定) または `python-sounddevice`
* **Signal Processing:** `librosa`, `numpy`
* **Compute:** NVIDIA GPU (CUDA) ※ただしリアルタイムループはCPU推奨
* **OS:** Linux (Realtime Kernel / PREEMPT_RT 推奨)
* **Deployment:** Docker (Host Audio Passthrough必須)

---

## 8. リポジトリ構成と成果物の置き場所（運用）

初めて触る人が迷子になりやすいため、資料と成果物の置き場所を固定する。

### 8.1. ドキュメント（docs/）
- `docs/ガイド.md`: 入口（この1本だけ追えばOK）
- `docs/spec/`: 仕様書（本書）
- `docs/howto/`: 手順書（遅延計測、MC探索など）
- `docs/project/`: チェックリスト等の進捗管理

### 8.2. 生成物（outputs/）
実験・計測の生成物は `outputs/` 配下に保存する。
- `outputs/phase1/latency/`: Phase 1 遅延計測の JSONL ログ（stopイベント単位）
- `outputs/phase1/report/`: Phase 1 の測定結果まとめ（Markdown）
- `outputs/phase2/mc/runs/`: Phase 2（MC探索）の生CSV
- `outputs/phase2/mc/reports/`: Phase 2（MC探索）の集計レポート（Markdown）

※ 生成物はサイズが増えるため、Git管理するかは運用ポリシーに従う。
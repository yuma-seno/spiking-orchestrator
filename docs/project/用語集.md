# 用語集（非エンジニア向け）

このプロジェクトは「音声の停止を素早く・安全に行う」ことから始めています。
ここでは、資料中に出てくる用語をざっくり理解できるように説明します。

<a id="glossary-stop"></a>
## Stop（停止）
話している途中でも、ユーザーが割り込んだら **すぐに音声を止める**こと。
体験としては「喋り続けない」「反応が遅れない」に直結します。

補足:
- 実装/設計では Stop を1種類にせず、目的の違いで分けて扱います（下記参照）。

<a id="glossary-hard-stop"></a>
## Hard Stop（ハード停止 / 安全停止）
安全のために **即時に音声を止める**停止。

特徴:
- 最優先で処理する（通常の通信経路が混んでいても止められる）
- 原則として例外なく止める（安全装置）

<a id="glossary-soft-interrupt"></a>
## Soft Interrupt（割り込み兆候 / Interrupt Cue）
ユーザが話し始めた・割り込みたい、などの **兆候（手がかり）**。

ポイント:
- これは「止めろ」という命令ではなく、Coreが能動的に判断するための入力
- 例: 「あと1単語で終わるなら話し切る」「重要説明なので“ちょっと待って”と言う」などは、Coreの判断（学習）で実現する

<a id="glossary-latency"></a>
## レイテンシ（遅延）
何かが起きてから反応するまでの時間。
ここでは主に「停止の判断をして止めるまで」の時間を測ります。

<a id="glossary-percentile"></a>
## p95 / p99（パーセンタイル）
ざっくり言うと「ほとんどのケースは速いけど、たまに遅い」が問題になります。
- **p95**: 100回中95回はこれ以下の遅延
- **p99**: 100回中99回はこれ以下の遅延

平均よりも **p99のような“たまに遅い”** が体験を壊しやすいので仕様書で重視しています。

<a id="glossary-reflex"></a>
## Reflex（反射回路）
「細かく考える前に、安全のために即反応する」仕組み。
このプロジェクトではまず「割り込みを検知して止める」役割です。

<a id="glossary-backchannel"></a>
## バックチャネル（相槌）
会話の流れを崩さずに「聞いている」ことを伝える短い発話。
例: 「あー」「えっと」「なるほど」など。

狙い:
- 思考層（RWKV等）の応答待ちの間を自然に繋ぐ
- ユーザの割り込み兆候に対して、即停止だけでなく自然な応答を可能にする

<a id="glossary-fast-path"></a>
## Fast Path（高速経路）
重い思考層（RWKV等）を呼ばずに、Coreだけで高速に返せる経路。

例:
- 同一/類似の質問が短時間に繰り返されたときのキャッシュ応答
- 定型の相槌・確認

<a id="glossary-interaction-policy"></a>
## Interaction Policy（対話方針 / Executive）
Coreが「いつ思考層を呼ぶか」「いつ何を話すか」「割り込みにどう応じるか」を決める方針。

方針:
- ルールのハードコーディングを増やしすぎず、学習で適応させる
- そのために必要な入力（観測）・出力（行動）・評価（ログ/KPI）を整備する

<a id="glossary-dsp-first"></a>
## DSP-first（古典的信号処理から始める）
最初から難しい学習モデルにせず、
まずは音量などの単純な特徴量で動く仕組みを作ってベースライン（基準値）を取る方針です。

<a id="glossary-snn"></a>
## SNN（スパイキングニューラルネットワーク）
脳のニューロンのように、連続値ではなく“スパイク（発火）”で情報をやり取りするモデル。
このプロジェクトでは SpikingJelly で試作しています。

<a id="glossary-single-snn-integration"></a>
## 単一SNN統合（Single SNN Integration）
Reflex（反射）とReservoir（短期記憶）など、複数の役割を **1つのSNNの中にまとめる**考え方。

ポイント:
- まとめること自体は可能（実装は自由度が高い）
- ただし **Hard Stop（安全停止）は統合の有無に関係なく独立に守る**のが前提（最優先経路でMotorへ直通）

<a id="glossary-region-partitioning"></a>
## 領域分割（Region Partitioning）
同じネットワーク（同じプロセス/同じSNN）の中でも、
「ここは固定重みで安全装置（Reflex）」「ここは可塑性で短期記憶（Reservoir）」のように **役割ごとに性質を分ける**こと。

狙い:
- 「1つにまとめて表現力は上げたい」一方で
- 「学習が安全装置を壊さない」ように守る（可塑性マスク/ゲートなど）

<a id="glossary-stp"></a>
## STP（短期可塑性）
短時間だけ反応が強くなったり弱くなったりする性質。
会話テンポの“勢い”を持たせるのに使えると期待しています。

<a id="glossary-mc"></a>
## Memory Capacity（MC）
短期記憶の強さを測る指標。
「少し前の入力を、今の状態からどれだけ復元できるか」を数値化します。

---

<a id="glossary-readout"></a>
## Readout（読み出し層）
リザーバ（脳っぽい回路）の「いまの状態」を見て、
最終的な出力（たとえば“止める/止めない”や“次の行動”）を決める **最後の薄い層**です。

ポイント:
- リザーバ本体は複雑でも、Readoutは **線形（足し算）** で済むことが多い
- 「何を見せるか（状態ベクトル設計）」が性能に効きやすい

<a id="glossary-state-vector"></a>
## 状態ベクトル（state vector）
ある時刻 $t$ におけるリザーバの内部状態を、数の並び（ベクトル）として取り出したもの。
例: 膜電位 `v`、スパイク `spike`、STP内部状態 `u/r/eff` など。

<a id="glossary-state-mode"></a>
## state_mode（状態ベクトルの選び方）
Readoutに渡す「状態ベクトル」を、どの信号の組み合わせにするかを表す指定です。
このリポジトリでは `v+spike+u+r+eff` のように `+` で連結して表します。

<a id="glossary-spike-rate"></a>
## spike_rate（発火率）
「1ステップ×1ニューロンあたり、平均でどれくらいスパイクが出ているか」の目安。

直感:
- 0に近い: ほぼ発火していない（動いていない）可能性
- 大きすぎる: 常に発火して飽和している可能性（これも記憶が出にくいことがある）

<a id="glossary-washout"></a>
## washout（ウォッシュアウト）
実験の最初は、状態が落ち着いていない“ならし運転”の時間があるため、
その区間を **評価から捨てる** ための設定です。

<a id="glossary-max-delay"></a>
## max_delay（最大遅れ）
MCで「どれくらい昔の入力まで復元できるか」を測るときの範囲。
`max_delay=120` なら「1〜120ステップ前」までを評価します。

<a id="glossary-ridge"></a>
## ridge（リッジ正則化）
Readoutを学習するときの“暴れ防止”の設定。
大きくすると学習が安定しやすい一方、当てはまりが弱くなることがあります。

<a id="glossary-random-projection"></a>
## Random Projection（ランダム射影）
高次元の状態ベクトルを、ランダムな行列で **低次元に圧縮** する方法。

狙い:
- 次元が大きいと計算が重い → 圧縮して軽くする
- できるだけ情報を壊さずに圧縮したい

<a id="glossary-rls"></a>
## RLS（Recursive Least Squares）
Readoutの重みを、データが流れてくるたびに **オンラインで更新** する学習法。
「ユーザーの会話テンポが変わる」などの変化に追従する用途を想定しています。

---

<a id="glossary-speech-plan"></a>
## Speech Plan（発話計画）
「何を言うか（文章）」と「どう言うか（話し方）」を分けて、Motor Cortexに渡すためのデータ。

※ 現在の仕様では、Speech Planはより一般的な Action Plan の一部（音声モダリティ向けの見方）として扱います。

狙い:
- 抑揚や言い直しまでOrchestratorに学習させると複雑になりすぎる
- そこでOrchestratorは **低次元のメタ情報**だけを渡し、音声表現の詳細はMotorが担当する

例（概念）:
- `text`: 発話テキスト
- `u`: 低次元の制御ベクトル（話し方の粗い指定）

<a id="glossary-action-plan"></a>
## Action Plan（行動計画：Speech Planの一般化）
将来、出力が音声だけでなく **マウス操作・キーボード入力・ロボット操作**などにも広がることを想定し、
「何を実行するか」を共通の枠組みでMotorへ渡すためのデータ。

ポイント:
- Core→MotorのI/F（項目）を増やさないために、基本は **任意テキスト + 低次元制御ベクトル $u(t) \in \mathbb{R}^K$** だけで表現する
- “話す”も“操作する”も「実行/中断/キャンセル/安全停止」を同じ発想で扱える
- ただしHard Stop（安全停止）は最優先で、学習や通常通信をバイパスして止められる必要がある

<a id="glossary-modality"></a>
## モダリティ（出力の種類）
ここでは「音声」「マウス」「キーボード」「ロボット」など、出力の種類のこと。

<a id="glossary-driver-adapter"></a>
## Driver / Adapter（デバイス制御の薄い層）
上位（Motorの実行制御）が決めたAction Planを、
実際のデバイス操作（OSイベント注入、オーディオ再生、ロボット制御など）に変換して実行する層。

狙い:
- モダリティごとの失敗モードや安全要件の違いをここに閉じ込める
- 上位（Core/Executive）は「何をする/止める」を学習しやすくする

<a id="glossary-prosody"></a>
## プロソディ（prosody, 抑揚・間・アクセント）
同じ文章でも「疑問っぽく聞こえる」「強調して聞こえる」など、話し方のニュアンスを決める要素。
句読点や文末（？/！）などのテキスト情報と、話し方メタ情報（Speech Plan）から生成します。

<a id="glossary-revision"></a>
## Revision（付け足し・言い直し）
発話の途中で「補足したい」「言い直したい」が起きたときに、音声再生を自然に更新すること。
このプロジェクトでは、短いチャンク単位で再生し、未来のチャンクを差し替える方式を想定します。

<a id="glossary-forgetting-factor"></a>
## 忘却係数（forgetting factor, lambda）
RLSで「昔のデータをどれくらい忘れるか」を決める値。

直感:
- 1.0に近い: ほぼ忘れない（安定だが追従が遅い）
- 小さめ: 早く忘れる（追従は速いが不安定になりやすい）

<a id="glossary-tikhonov"></a>
## Tikhonov正則化（チホノフ）
学習が不安定にならないように、重みが大きくなりすぎるのを抑える工夫。
このリポジトリではRLSやridgeの文脈で出てきます。
